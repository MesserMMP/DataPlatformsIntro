# üöÄ HW5: Data Processing Flow with Prefect + Apache Spark on YARN

–†–µ–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ—Ç–æ–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º [Prefect](https://docs.prefect.io/) –∏ Apache Spark –≤ –∫–ª–∞—Å—Ç–µ—Ä–µ, —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç–æ–º —Ä–∞–Ω–µ–µ.

---

## üì¶ 0. –ü—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–∫–∏

–ü–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤ –≤–∞—à–µ–º –æ–∫—Ä—É–∂–µ–Ω–∏–∏:

- –†–∞–∑–≤—ë—Ä–Ω—É—Ç –∫–ª–∞—Å—Ç–µ—Ä Hadoop —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π YARN.
- –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω Hive —Å –≤–Ω–µ—à–Ω–∏–º Metastore.
- –§–∞–π–ª `electric_vehicles.csv` –∑–∞–≥—Ä—É–∂–µ–Ω –≤ HDFS –ø–æ –ø—É—Ç–∏ `/input`.
- –ù–∞ –≥–ª–∞–≤–Ω–æ–º —É–∑–ª–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω Python 3.12 –∏ –¥–æ—Å—Ç—É–ø–Ω—ã —É—Ç–∏–ª–∏—Ç—ã `pip`, `venv`.
- –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ —É–∫–∞–∑–∞–Ω—ã –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
---

## üñ•Ô∏è 1. –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∫–ª–∞—Å—Ç–µ—Ä—É

–ü–æ–¥–∫–ª—é—á–∏—Ç–µ—Å—å –∫ –≥–ª–∞–≤–Ω–æ–º—É —É–∑–ª—É –∏ –ø–µ—Ä–µ–π–¥–∏—Ç–µ –ø–æ–¥ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è `hadoop`.

```bash
ssh -L 9870:127.0.0.1:9870 -L 8088:127.0.0.1:8088 -L 19888:127.0.0.1:19888 team@<JUMP-HOST-IP>
sudo -i -u hadoop
```

> üîÅ –ó–∞–º–µ–Ω–∏—Ç–µ `<JUMP-HOST-IP>` –Ω–∞ IP-–∞–¥—Ä–µ—Å –≤–∞—à–µ–π jump-–Ω–æ–¥—ã.

---

## ‚öôÔ∏è 2. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è Python

–°–æ–∑–¥–∞–π—Ç–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ –∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ `Prefect`:

```bash
cd ~
python3 -m venv venv
source venv/bin/activate
pip install prefect
```

---

## üßæ 3. –°–æ–∑–¥–∞–Ω–∏–µ ETL-–ø–æ—Ç–æ–∫–∞ –≤ `Prefect`

–°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª `etl_flow.py`:

```bash
vim etl_flow.py
```

–í—Å—Ç–∞–≤—å—Ç–µ —Å–ª–µ–¥—É—é—â–∏–π –∫–æ–¥:

```python
from pyspark.sql import SparkSession, functions as F
from onetl.connection import SparkHDFS, Hive
from onetl.file import FileDFReader
from onetl.file.format import CSV
from onetl.db import DBWriter
from prefect import flow, task

@task
def get_spark():
    spark = SparkSession.builder \
        .master("yarn") \
        .appName("spark-with-yarn") \
        .config("spark.sql.warehouse.dir", "/user/hive/warehouse") \
        .config("spark.hive.metastore.uris", "thrift://tmpl-jn:9083") \
        .enableHiveSupport() \
        .getOrCreate()
    return spark

@task
def stop_spark(spark):
    spark.stop()

@task
def extract(spark):
    hdfs = SparkHDFS(host="tmpl-nn", port=9000, spark=spark, cluster="test")
    reader = FileDFReader(connection=hdfs, format=CSV(delimiter=",", header=True), source_path="/input")
    df = reader.run(["electric_vehicles.csv"])
    return df

@task
def transform(df):
    df_cleaned = df.withColumn("Model Year", F.col("Model Year").cast("int"))  # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–∏–ø–æ–≤
    df_agg = df_cleaned.groupBy("Make").count().orderBy("count", ascending=False)  # –ê–≥—Ä–µ–≥–∞—Ü–∏—è
    return df_agg

@task
def load(spark, df):
    hive = Hive(spark=spark, cluster="test")
    writer = DBWriter(connection=hive, table="test.ev_aggregated_counts",
                      options={"if_exists": "replace_entire_table"})
    writer.run(df)

@flow
def process_data():
    spark = get_spark()
    df = extract(spark)
    df = transform(df)
    load(spark, df)
    stop_spark(spark)

if __name__ == "__main__":
    process_data()
```

---

## ‚ñ∂Ô∏è 4. –ó–∞–ø—É—Å–∫ –ø–æ—Ç–æ–∫–∞

```bash
python etl_flow.py
```

–ü–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω–∞ –Ω–æ–≤–∞—è —Ç–∞–±–ª–∏—Ü–∞ `ev_aggregated_counts` –≤ Hive.

üñºÔ∏è *–°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Ç–∞–±–ª–∏—Ü –∏–∑ web-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞:*

![All_tables](./screenshots/all_tables.png)

---

## üîç 5. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —á–µ—Ä–µ–∑ Hive CLI

–ü–æ–¥–∫–ª—é—á–∏—Ç–µ—Å—å –∫ `Hive`:

```bash
beeline -u jdbc:hive2://tmpl-jn:5432 -n scott -p tiger
```

–í—ã–ø–æ–ª–Ω–∏—Ç–µ SQL-–∑–∞–ø—Ä–æ—Å:

```sql
USE test;
SHOW TABLES;
SELECT * FROM ev_aggregated_counts LIMIT 10;
```

üñºÔ∏è *–ü—Ä–∏–º–µ—Ä –≤—ã–≤–æ–¥–∞:*

![sql_results](./screenshots/sql_results.png)

---

## ‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç

- –î–∞–Ω–Ω—ã–µ –±—ã–ª–∏ –ø—Ä–æ—á–∏—Ç–∞–Ω—ã –∏–∑ HDFS –ø—Ä–∏ –ø–æ–º–æ—â–∏ Spark.
- –í—ã–ø–æ–ª–Ω–µ–Ω–∞ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö:
  - –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ —Ç–∏–ø–∞ —Å—Ç–æ–ª–±—Ü–∞ `Model Year` –∫ `int`.
- –í—ã–ø–æ–ª–Ω–µ–Ω–∞ –∞–≥—Ä–µ–≥–∞—Ü–∏—è:
  - –ü–æ–¥—Å—á–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∞–≤—Ç–æ–º–æ–±–∏–ª–µ–π –ø–æ –±—Ä–µ–Ω–¥—É (`Make`).
  - –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —É–±—ã–≤–∞–Ω–∏—é –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞.
- –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –∫–∞–∫ —Ç–∞–±–ª–∏—Ü–∞ –≤ Hive (`ev_aggregated_counts`).
- –í–µ—Å—å –ø—Ä–æ—Ü–µ—Å—Å —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω –≤ –≤–∏–¥–µ –ø–æ—Ç–æ–∫–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Prefect.

---
